<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Peide Huang</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/cmu_icon.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Peide Huang</name>
              </p>
              <p>I am a second-year Ph.D. student advised by Prof. <a href="https://www.meche.engineering.cmu.edu/directory/bios/zhao-ding.html">Ding Zhao</a> @ <a href="https://safeai-lab.github.io/">SafeAI Lab</a> and co-advised by Prof. <a href="https://feifang.info/">Fei Fang</a> @ <a href="https://feifang.info/group/">AI and Social Good Lab</a> at Carnegie Mellon University. Prior to joining CMU, I received my Bachelor's degree from Nanyang Technological University, Singapore and Master's degree from Stanford University.
              </p>
              <p>
              My research goal is to understand the interaction between the reinforcement learning agent and the tasks, with the objective to enable robust, safe, and explainable decision making. To achieve this goal, I leverage curriculum learning, representation learning, and game theory. I also tackle real-world applications in robotics and autonomous driving.
              </p>
              <p style="text-align:center">
                <a href="mailto:peideh@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                <a href="data/Resume_Peide_Huang.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=g5U-sjoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/huang_peide">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/PeideHuang/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/peidehuang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/peidehuang_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <hr>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rrl-stack.png" alt="hpp" style="border-style: none" width="300">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a>
                <a href="https://arxiv.org/pdf/2202.09514.pdf"><papertitle>Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training
                </papertitle></a>
              </a>
              <br>
              <strong>Peide Huang</strong>, Mengdi Xu,
              <a href="https://feifang.info/">Fei Fang</a>, 
              <a href="https://www.meche.engineering.cmu.edu/directory/bios/zhao-ding.html">Ding Zhao</a>
              <br>
              <em>Preprint, under review</em>
              <br>
              <!-- <a href="https://arxiv.org/pdf/2202.09514.pdf">Paper</a> / -->
              <a href="data/rrl.txt">bibtex</a>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gdrl.png" alt="hpp" style="border-style: none" width="300">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a>
                <papertitle>Group Distributionally Robust Reinforcement Learning
                </papertitle>
              </a>
              <br>
              Mengdi Xu, <strong>Peide Huang</strong>, Visak Kumar, Jielin Qiu, Chao Fang, Kuan-Hui Lee, Xuewei Qi, Henry Lam, Bo Li,
              <a href="https://www.meche.engineering.cmu.edu/directory/bios/zhao-ding.html">Ding Zhao</a>.
              <br>
              <em>Preprint, under review</em>
              <br>
              <!-- <a href="https://arxiv.org/pdf/2106.10566.pdf">Paper</a> / -->
              <!-- <a href="data/ape.txt">bibtex</a> -->
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/LGA.png" alt="hpp" style="border-style: none" width="300">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a>
                <a href="http://bayesiandeeplearning.org/2021/papers/58.pdf"><papertitle>Latent Goal Allocation for Multi-Agent Goal-Conditioned Self-Supervised Imitation Learning
                </papertitle></a> 
              </a>
              <br>
              <strong>Peide Huang</strong>*,
              Laixi Shi*,
              Rui Chen*. Equal contribution
              <!-- <br> -->
              <!-- <em>Preprint, under review</em> -->
              <br>
              <!-- <a href="http://bayesiandeeplearning.org/2021/papers/58.pdf">Paper</a>  / -->
              <a href="data/lga.txt">bibtex</a>
              <br>
              NeurIPS 2021 Workshop in Bayesian Deep Learning.
              <a href="http://bayesiandeeplearning.org/">Workshop</a> 
              <!-- / <a href="data/APE_ICLR2021Workshop_poster.pdf">Poster</a> -->
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/APE.png" alt="hpp" style="border-style: none" width="300">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a>
                <a href="https://arxiv.org/pdf/2106.10566.pdf"><papertitle>Accelerated Policy Evaluation: Learning Adversarial Environments with Adaptive Importance Sampling
                </papertitle></a>
              </a>
              <br>
              Mengdi Xu,
              <strong>Peide Huang</strong>,
              Fengpei Li,
              Jiacheng Zhu,
              Xuewei Qi,
              Kentaro Oguchi,
              <a href="https://sites.google.com/view/zyhuang">Zhiyuan Huang</a>,
              <a href="http://www.columbia.edu/~khl2114/">Henry Lam</a>,
              <a href="https://www.meche.engineering.cmu.edu/directory/bios/zhao-ding.html">Ding Zhao</a>
              <br>
              <em>Preprint, under review</em>
              <br>
              <!-- <a href="https://arxiv.org/pdf/2106.10566.pdf">Paper</a> / -->
              <a href="data/ape.txt">bibtex</a>
              <br>
              Abridged in ICLR 2021 Workshop in Security and Safety in Machine Learning Systems.
              <a href="https://aisecure-workshop.github.io/aml-iclr2021/">Workshop</a> /
              <a href="data/APE_ICLR2021Workshop_poster.pdf">Poster</a>
            </td>
          </tr>
				
<!--           <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:0%;vertical-align:middle">
              *: Equal contribution
            </td>
          </tr> -->
        </tbody></table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
              <hr>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/24677.png" alt="hpp" style="border-style: none" width="300">
            </td>
            <td width="75%" valign="center">
              <a href="https://safeai-lab.github.io/lcs-fall2021.html">Head of teaching assistants, Modern Control, Fall 2021</a>
              <br>
              <br>
              <a href="https://safeai-lab.github.io/lcs-fall2020.html">Head of teaching assistants, Linear Control Systems, Fall 2020</a>
              <br>
              <br>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>News</heading>
              <hr>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="100%" valign="center">
              <li>2/4/2022: I just passed my Ph.D. qualification exam!</li>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Side Fun Projects</heading>
              <hr>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="100%" valign="center">
              <li><a href="https://www.youtube.com/watch?v=HOhLT9md4TM">Autonomous Vehicle Racing</a></li>
              <li><a href="https://www.youtube.com/watch?v=0GoRiBrYU6w">The Remote-controlled Walking Robot: Eletric Beest</a></li>
              <li><a href="https://www.youtube.com/watch?v=8HiO4uXJZPQ">The Autonomous "Garbage" Collection Robot</a></li>
              <li><a href="https://www.youtube.com/watch?v=b-o1qhRA3cc">Multi-agent System Coverage with Time-variant Density Function</a></li>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
